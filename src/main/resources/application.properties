#链接
crawler.url=http://www.ncpa-classic.com/
#名称
crawler.name=test
#开始的章节，如果是全部则不填
crawler.chapter.start=Raw Chapter 68
#只下某章节，优先顺序比上面（crawler.chapter.start）的高，即这个设置了crawler.chapter.start则不生效
crawler.chapter=
#保存的文件夹地址
crawler.save.path=E:/temp/crawler
#规则目录存放文件夹地址
crawler.rule.path=







#保存地址
save.path=${crawler.save.path}/${crawler.name}
#是否开启多线程下载
download.use.multithreading.enable=true

#规则类型
rule.action.type=jsonRuleAction
#找不到对应的规则文件时是否使用默认值
use.default.rule.file=true

#请求相关配置
#请求超时时间,默认20秒
request.timeout=20000
#等待异步JS执行时间,默认20秒
request.wait.for.background.java.script=20000
#获取html方式的类型，默认htmlUnit.有htmlUnit,jsoup
request.type=jsoup
#客户端接受的响应类型
request.accept=*/*
#请求设备
request.user.agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/74.0.3729.169 Safari/537.36
#指示资源的MIME类型
request.content.type=text/html; charset=UTF-8

#同时下载几页
download.manga.thread.pool.size=10
#同时下载几话
download.chapter.thread.pool.size=3

#10秒钟内没有任务就关闭线程池
download.manga.thread.pool.timeout=10
#10秒钟内没有任务就关闭线程池
download.chapter.thread.pool.timeout=10